{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX_gwSZ_6ZKO"
      },
      "source": [
        "# **Tugas Besar C - IF3270 Pembelajaran Mesin**\n",
        "Authors:\n",
        "\n",
        "1. 13519096 Girvin Junod\n",
        "\n",
        "2. 13519116 Jeane Mikha Erwansyah\n",
        "\n",
        "3. 13519131 Hera Shafira\n",
        "\n",
        "4. 13519188 Jeremia Axel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHAq5ADxPg6U"
      },
      "source": [
        "## Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-uXAhZ5Pt6V"
      },
      "outputs": [],
      "source": [
        "# !pip install icecream\n",
        "# !pip install networkx\n",
        "# !pip install pandas\n",
        "# !pip install numpy\n",
        "# !pip install matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6_VuJbZ64yD"
      },
      "source": [
        "## Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tP_mwtuv4W_7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os, subprocess, sys\n",
        "import json, math, typing, copy\n",
        "import numpy as np, networkx as nx, matplotlib.pyplot as plt\n",
        "import json\n",
        "# from icecream import ic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNnoGGyB7W42"
      },
      "source": [
        "## Enums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8Qalm1u7Zl-"
      },
      "outputs": [],
      "source": [
        "class ActivationTypes:\n",
        "\tSIGMOID = \"sigmoid\"\n",
        "\tRELU = \"relu\"\n",
        "\tSOFTMAX = \"softmax\"\n",
        "\tLINEAR = \"linear\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGxBGS587e6q"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztAH1zztGkcj"
      },
      "outputs": [],
      "source": [
        "class Utils:\n",
        "\t@staticmethod\n",
        "\tdef get_activation_func(activation_type: str):\n",
        "\t\tif activation_type == 'sigmoid':\n",
        "\t\t  return ActivationTypes.SIGMOID\n",
        "\t\telif activation_type == 'linear':\n",
        "\t\t  return ActivationTypes.LINEAR\n",
        "\t\telif activation_type == 'relu':\n",
        "\t\t  return ActivationTypes.RELU\n",
        "\t\telif activation_type == 'softmax':\n",
        "\t\t  return ActivationTypes.SOFTMAX\n",
        "\t\t\t\n",
        "\t@staticmethod\n",
        "\tdef install(package):\n",
        "\t\tsubprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", ''.join(package)])\n",
        "\t\n",
        "\t@staticmethod\n",
        "\tdef listdivision(arr1, arr2):\n",
        "\t\t'''\n",
        "\t\tFungsi untuk pembagian list dengan panjang sama\n",
        "\t\tAsumsi untuk zero division nilai yang diberikan adalah 0\n",
        "\t\t'''\n",
        "\t\tret= []\n",
        "\t\tfor i in range(len(arr1)):\n",
        "\t\t\tif (arr2[i] !=0):\n",
        "\t\t\t\tret.append(arr1[i]/arr2[i])\n",
        "\t\t\telse:\n",
        "\t\t\t\tret.append(0)\n",
        "\t\treturn ret\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef confusionMatrix(true, pred):\n",
        "\t\t'''\n",
        "\t\ttrue: array of true values\n",
        "\t\tpred: array of predicted values\n",
        "\t\t'''\n",
        "\t\tnum_class = len(np.unique(true))\n",
        "\t\tresult = np.zeros((num_class, num_class))\n",
        "\n",
        "\t\tfor i in range(len(true)):\n",
        "\t\t\tresult[true[i]][pred[i]] += 1\n",
        "\n",
        "\t\treturn result\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef getTP(cm):\n",
        "\t\t#total diagonal cm\n",
        "\t\treturn np.diag(cm)\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef getTN(cm):\n",
        "\t\t#Semua kecuali cell kelas dan row col dari kelas\n",
        "\t\tTN = []\n",
        "\t\tfor i in range(len(cm)):\n",
        "\t\t\t\ttemp = np.delete(cm, i, 0)   \n",
        "\t\t\t\ttemp = np.delete(temp, i, 1) \n",
        "\t\t\t\tTN.append(sum(sum(temp)))\n",
        "\t\treturn TN\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef getFP(cm):\n",
        "\t\t#total di kolom kecuali cell class\n",
        "\t\treturn np.sum(cm, axis=0) - Utils.getTP(cm)\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef getFN(cm):\n",
        "\t\t#total di row kecuali cell kelas\n",
        "\t\treturn np.sum(cm, axis=1) - Utils.getTP(cm)\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef accuracy(true, pred) -> float:\n",
        "\t\t#true/total\n",
        "\t\tbenar = 0\n",
        "\t\tfor i in range(len(true)):\n",
        "\t\t\tif (true[i] == pred[i]):\n",
        "\t\t\t\tbenar+=1\n",
        "\n",
        "\t\treturn benar/len(true)\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef precision(true, pred) -> float:\n",
        "\t\t#true positive/(truepositive + false positive)\n",
        "\t\t#true positive/(total pred positive)\n",
        "\t\tnum_class = len(np.unique(true))\n",
        "\t\ttotal = 0\n",
        "\t\tcm = Utils.confusionMatrix(true, pred)\n",
        "\t\tTP = Utils.getTP(cm)\n",
        "\t\tFP = Utils.getFP(cm)\n",
        "\t\tprec= Utils.listdivision(TP,(TP+FP))\n",
        "\t\ttotal = np.sum(prec)/num_class\n",
        "\t\treturn total\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef recall(true, pred) -> float:\n",
        "\t\t#true positive/(true positive + false negative)\n",
        "\t\t#true positive/(total actual positive)\n",
        "\t\tnum_class = len(np.unique(true))\n",
        "\t\ttotal = 0\n",
        "\t\tcm = Utils.confusionMatrix(true, pred)\n",
        "\t\tTP = Utils.getTP(cm)\n",
        "\t\tFN = Utils.getFN(cm)\n",
        "\t\trec = Utils.listdivision(TP,(TP+FN))\n",
        "\t\t\n",
        "\t\ttotal = np.sum(rec)/num_class\n",
        "\t\treturn total\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef f1(true, pred) -> float:\n",
        "\t\t#2*(precision*recall)/(precision+recall)\n",
        "\t\t#TP/(TP+ 0.5(FP+FN))\n",
        "\n",
        "\t\tcm = Utils.confusionMatrix(true, pred)\n",
        "\t\tTP = Utils.getTP(cm)\n",
        "\t\tFN = Utils.getFN(cm)\n",
        "\t\tFP = Utils.getFP(cm)\n",
        "\t\tf = TP/(TP+ 0.5*(FP+FN))\n",
        "\t\treturn np.sum(f)/len(np.unique(true))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xxTZUlloj6H"
      },
      "outputs": [],
      "source": [
        "class Activations:\n",
        "  @staticmethod\n",
        "  def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "  @staticmethod\n",
        "  def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "  @staticmethod\n",
        "  def linear(x):\n",
        "    return x\n",
        "  @staticmethod\n",
        "  def softmax(x):\n",
        "    e_x = np.exp(x-np.max(x))\n",
        "    return e_x/e_x.sum(axis=1).reshape(-1,1)\n",
        "  @staticmethod\n",
        "  def d_sigmoid(x):\n",
        "    return Activations.sigmoid(x) * (1 - Activations.sigmoid(x))\n",
        "  @staticmethod\n",
        "  def d_linear(x):\n",
        "    return np.ones(x.shape)\n",
        "  @staticmethod\n",
        "  def d_relu(x):\n",
        "    return (x>=0).astype(int)\n",
        "  @staticmethod\n",
        "  def d_softmax(x, y):\n",
        "    # x itu de_dnet\n",
        "    x[np.arange(y.flatten().shape[0]), y.flatten()] = -(1-x[np.arange(y.flatten().shape[0]), y.flatten()])\n",
        "    return x*-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRyyj_QlGqfk"
      },
      "source": [
        "## Layer Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QC9FJsPWGu57"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "\tdef __init__(self, num_nodes: int, activation_func, weights=None, prev_nodes=None):\n",
        "\t\tif weights!=None:\n",
        "\t\t\tself.weights = weights\n",
        "\t\telse:\n",
        "\t\t\tself.weights = np.random.standard_normal((prev_nodes, num_nodes))\n",
        "\t\t\tself.weights = np.r_[np.zeros((1, num_nodes)), self.weights]\n",
        "\t\tself.num_nodes = num_nodes\n",
        "\t\tself.activation_func = activation_func\n",
        "\n",
        "\tdef layer_dict(self):\n",
        "\t\treturn {\n",
        "\t\t\t\"weights\" : self.weights.tolist(),\n",
        "\t\t\t\"num_nodes\":self.num_nodes,\n",
        "\t\t\t\"activation_function\":self.activation_func\n",
        "\t\t}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTc9FvzzG7O-"
      },
      "source": [
        "## Graph Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_vqOVy7G-Gn"
      },
      "outputs": [],
      "source": [
        "class Graph:\n",
        "\tdef __init__(self, input_count=None, n_layers=None, n_neurons=None, activation_funcs=None, file_name=None):\n",
        "\t\t'''\n",
        "\t\tinput_count: int\n",
        "\t\t\tJumlah elemen input\n",
        "\t\tn_layers: int\n",
        "\t\t\tJumlah layer\n",
        "\t\tn_neurons: list[int]\n",
        "\t\t\tJumlah neuron untuk tiap layer\n",
        "\t\tactivation_func: list[ActivationTypes]\n",
        "\t\t\tFungsi aktivasi untuk tiap layer\n",
        "\t\t'''\n",
        "\t\tself.layers = []\n",
        "\t\tself.loss = []\n",
        "\t\tif file_name!=None:\n",
        "\t\t\tself.load_graph(file_name)\n",
        "\t\telse:\n",
        "\t\t\tif n_layers is not None:\n",
        "\t\t\t\tself.n_layer = n_layers\n",
        "\t\t\t\tfor i in range(self.n_layer):\n",
        "\t\t\t\t\tif (i==0):\n",
        "\t\t\t\t\t\tnew_layer = Layer(n_neurons[i], activation_funcs[i], None, input_count)\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tnew_layer = Layer(n_neurons[i], activation_funcs[i], None, self.layers[i-1].num_nodes)\n",
        "\t\t\t\t\tself.add_layer(new_layer)\n",
        "\t\t\t\tself.output_activation = self.layers[len(self.layers)-1].activation_func\n",
        "\t\n",
        "\tdef add_layer(self, layer: Layer):\n",
        "\t\tself.layers.append(layer)\n",
        "\n",
        "\tdef get_layer_output(self, layer: Layer, inputs: np.array):\n",
        "\t\tlayer.inputs = np.c_[np.ones((inputs.shape[0], 1)), inputs]\n",
        "\t\tlayer.net_value = np.dot(layer.inputs, layer.weights)\n",
        "\t\n",
        "\t\tif layer.activation_func == ActivationTypes.SIGMOID:\n",
        "\t \t\tlayer.output = Activations.sigmoid(layer.net_value)\n",
        "\t\telif layer.activation_func == ActivationTypes.RELU:\n",
        "\t\t\tlayer.output = Activations.relu(layer.net_value)\n",
        "\t\telif layer.activation_func == ActivationTypes.LINEAR:\n",
        "\t\t\tlayer.output = Activations.linear(layer.net_value)\n",
        "\t\telif layer.activation_func == ActivationTypes.SOFTMAX:\n",
        "\t\t\tlayer.output = Activations.softmax(layer.net_value)\n",
        "\t\t\n",
        "\tdef predict(self, x: np.ndarray):\n",
        "\t\tfor i in range(len(self.layers)):\n",
        "\t\t\tif i==0:\n",
        "\t\t\t\tself.get_layer_output(self.layers[i], x)\n",
        "\t\t\telse:\n",
        "\t\t\t\tself.get_layer_output(self.layers[i], self.layers[i-1].output)\n",
        "\t\treturn self.layers[len(self.layers)-1].output\n",
        "\t\t\n",
        "\tdef get_layer_deriv(self, delta: np.ndarray, lr: float, layer: Layer, y: np.ndarray = None):\n",
        "\t\tif y is not None:\n",
        "\t\t\tif layer.activation_func == ActivationTypes.SIGMOID:\n",
        "\t\t\t\tde_dnet = Activations.d_sigmoid(layer.net_value) * (y-layer.output)\n",
        "\t\t\telif layer.activation_func == ActivationTypes.RELU:\n",
        "\t\t\t\tde_dnet = Activations.d_relu(layer.net_value) * (y-layer.output)\n",
        "\t\t\telif layer.activation_func == ActivationTypes.LINEAR:\n",
        "\t\t\t\tde_dnet = Activations.d_linear(layer.net_value) * (y-layer.output)\n",
        "\t\t\telif layer.activation_func == ActivationTypes.SOFTMAX:\n",
        "\t\t\t\tde_dnet = Activations.d_softmax(layer.output, y)\n",
        "\t\telse:\n",
        "\t\t\tif layer.activation_func == ActivationTypes.SIGMOID:\n",
        "\t\t\t\tde_dnet = delta * Activations.d_sigmoid(layer.net_value)\n",
        "\t\t\telif layer.activation_func == ActivationTypes.RELU:\n",
        "\t\t\t\tde_dnet = delta * Activations.d_relu(layer.net_value)\n",
        "\t\t\telif layer.activation_func == ActivationTypes.LINEAR:\n",
        "\t\t\t\tde_dnet = delta * Activations.d_linear(layer.net_value)\n",
        "\n",
        "\t\tderiv = np.dot(np.transpose(de_dnet), layer.inputs)\n",
        "\t\tgrad = np.dot(de_dnet, np.transpose(layer.weights))[:,1:]\n",
        "\t\tlayer.weights += lr*np.transpose(deriv)\n",
        "\t\treturn grad\n",
        "\t\n",
        "\tdef backpropagate(self, learning_rate, y):\n",
        "\t\tdelta = self.get_layer_deriv(None, learning_rate, self.layers[len(self.layers)-1], y)\t\n",
        "\t\tfor i in range(len(self.layers)-2,-1,-1):\n",
        "\t\t\tdelta = self.get_layer_deriv(delta, learning_rate, self.layers[i])\n",
        "\t\t\t\n",
        "\tdef error(self, yhat: np.ndarray, y: np.ndarray, activation_func: ActivationTypes):\n",
        "\t\tif activation_func == ActivationTypes.SOFTMAX:\n",
        "\t\t\treturn -np.log(yhat[np.arange(yhat.shape[0]), y.flatten()]).sum()/yhat.shape[0]\n",
        "\t\telse:\n",
        "\t\t\treturn np.sum(np.square(y-yhat))/2\n",
        "\n",
        "\tdef train(self, x_train: np.ndarray, y_train: np.ndarray, lr, err_thresh, batch_size, max_iter=10000, print_per_iter=-1):\n",
        "\t\t'''\n",
        "\t\tx_train: np.ndarray\n",
        "\t\t\tInput training\n",
        "\t\ty_train: np.ndarray\n",
        "\t\t\tOutput dari x_train\n",
        "\t\tlr: float\n",
        "\t\t\tLearning rate\n",
        "\t\terr_thresh: float\n",
        "\t\t\tError threshold\n",
        "\t\tmax_iter: int\n",
        "\t\t\tJumlah maksimum iterasi\n",
        "\t\tprint_per_iter: int\n",
        "\t\t\tPrint nilai error setiap berapa iterasi\n",
        "\t\t'''\n",
        "\t\tcount_iter = 0\n",
        "\t\twhile True:\n",
        "\t\t\terr = 0\n",
        "\t\t\tall_batch_x = []\n",
        "\t\t\tall_batch_y = []\n",
        "\t\t\tn_batches = x_train.shape[0]//batch_size\n",
        "\n",
        "\t\t\tfor i in range(n_batches):\n",
        "\t\t\t\tmini_batch_x=x_train[i*batch_size:(i+1)*batch_size,:]\n",
        "\t\t\t\tall_batch_x.append(mini_batch_x)\n",
        "\n",
        "\t\t\t\tmini_batch_y=y_train[i*batch_size:(i+1)*batch_size,:]\n",
        "\t\t\t\tall_batch_y.append(mini_batch_y)\n",
        "\n",
        "\t\t\tif x_train.shape[0]%batch_size!=0:\n",
        "\t\t\t\tmini_batch_x=x_train[(i+1)*batch_size:,:]\n",
        "\t\t\t\tall_batch_x.append(mini_batch_x)\n",
        "\n",
        "\t\t\t\tmini_batch_y=y_train[(i+1)*batch_size:,:]\n",
        "\t\t\t\tall_batch_y.append(mini_batch_y)     \n",
        "\t\t\n",
        "\t\t\t\tn_batches+=1\n",
        "\n",
        "\t\t\tfor i in range(n_batches):\n",
        "\t\t\t\tyhat = self.predict(all_batch_x[i])\n",
        "\t\t\t\terr += self.error(yhat, all_batch_y[i], self.output_activation)\n",
        "\t\t\t\tself.backpropagate(lr, all_batch_y[i])\n",
        "\t\t\t\n",
        "\n",
        "\t\t\tself.loss.append(err)\n",
        "\t\t\tcount_iter+= 1\n",
        "\t\t\tif count_iter % print_per_iter == 0 and print_per_iter != -1:\n",
        "\t\t\t\tprint(f'Iterasi {count_iter}: error {err:.7f}')\n",
        "\t\t\tif count_iter >= max_iter:\n",
        "\t\t\t\tif print_per_iter != -1:\n",
        "\t\t\t\t\tprint(\"Iterasi maksimum\")\n",
        "\t\t\t\tbreak\n",
        "\t\t\tif err <= err_thresh:\n",
        "\t\t\t\tif print_per_iter != -1:\n",
        "\t\t\t\t\tprint(\"Mencapai nilai error di bawah batas\")\n",
        "\t\t\t\tbreak\n",
        "\t\tif print_per_iter != -1:\n",
        "\t\t\tprint(f'Berakhir pada iterasi: {count_iter}')\n",
        "\t\t\tprint(f'Nilai error final: {err}')\n",
        "\t\t\n",
        "\tdef display_table(self):\n",
        "\t\tfor i,layer in enumerate(self.layers):\n",
        "\t\t\tprint(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "\t\t\tprint(f'Layer {i}:')\n",
        "\t\t\tprint()\n",
        "\t\t\tprint(\"Weights:\")\n",
        "\t\t\tprint(layer.weights)\n",
        "\t\t\tprint()\n",
        "\t\t\tprint(f\"Activation Function: {layer.activation_func}\")\n",
        "\t\t\tprint(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "\t\t\tprint()\n",
        "\t\tprint(f\"Jumlah hidden layer: {self.n_layer - 1}\")\n",
        "\t\n",
        "\tdef export_graph(self):\n",
        "\t\tall_dict = []\n",
        "\t\tfor layer in self.layers:\n",
        "\t\t\tall_dict.append(layer.layer_dict())\n",
        "\t\tjson_obj = json.dumps(all_dict, indent=4)\n",
        "\t\twith open(\"model.json\", \"w\") as outfile:\n",
        "\t\t\t\toutfile.write(json_obj)\n",
        "\t\t\n",
        "\tdef load_graph(self, filename: str):\n",
        "\t\twith open(filename, 'r') as openfile:\n",
        "\t\t\tjson_object = json.load(openfile)\n",
        "\t\tfor obj in json_object:\n",
        "\t\t\tnew_layer = Layer(obj[\"num_nodes\"], obj[\"activation_function\"], obj[\"weights\"], None)\n",
        "\t\t\tself.layers.append(new_layer)\n",
        "\t\n",
        "\tdef loss_graph(self, label=\"Loss\"):\n",
        "\t\tplt.plot(range(0, len(self.loss)), self.loss , label=label)\n",
        "\t\tplt.title(label)\n",
        "\t\tplt.xlabel('Epoch')\n",
        "\t\tplt.ylabel('Loss')\n",
        "\t\tplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQK0SFh3HHra"
      },
      "source": [
        "## Main Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9LICNdPuRVe"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUBdZGY5ST3a"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn import metrics\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "iris = datasets.load_iris()\n",
        "x, y = iris.data, iris.target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediksi Batch"
      ],
      "metadata": {
        "id": "tCG3rYHtCLZt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNczwjWwvdgp"
      },
      "source": [
        "#### Create Neural Network and Train"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Neural Network Hasil Implementasi"
      ],
      "metadata": {
        "id": "h0taPAap6_yD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWt46uXiunZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43de3e16-eea4-4a43-c5d5-87e6151401a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iterasi 1000: error 0.3458198\n",
            "Iterasi 2000: error 0.1991806\n",
            "Iterasi 3000: error 0.1324378\n",
            "Iterasi 4000: error 0.1180149\n",
            "Iterasi 5000: error 0.1132253\n",
            "Iterasi 6000: error 0.1107779\n",
            "Iterasi 7000: error 0.1092365\n",
            "Iterasi 8000: error 0.1081487\n",
            "Iterasi 9000: error 0.1073258\n",
            "Iterasi 10000: error 0.1066737\n",
            "Iterasi maksimum\n",
            "Berakhir pada iterasi: 10000\n",
            "Nilai error final: 0.10667366707501996\n"
          ]
        }
      ],
      "source": [
        "#input_count, n_layers, n_neurons, activation_funcs\n",
        "graf = Graph(len(iris.feature_names), 2, [3, len(iris.target_names)], ['sigmoid', 'softmax'])\n",
        "#x, y, learning rate, error threshold, batch size, max iter?, print per iter?\n",
        "graf.train(x, y.reshape(-1,1), 1e-2, 2e-2,50, print_per_iter=1000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graf.export_graph()"
      ],
      "metadata": {
        "id": "2jI6w32HIxzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Neural Network MLPClassifier Sklearn"
      ],
      "metadata": {
        "id": "76DNfElDCBaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sklearn= MLPClassifier(hidden_layer_sizes=(3,), activation='logistic', max_iter=10000, batch_size=50, learning_rate='constant', learning_rate_init=1e-2)\n",
        "sklearn.fit(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jez9DcazCUPu",
        "outputId": "b8dc7c88-163a-4bc0-fb69-b4252ed55bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='logistic', batch_size=50, hidden_layer_sizes=(3,),\n",
              "              learning_rate_init=0.01, max_iter=10000)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ejvK3uiwhKy"
      },
      "source": [
        "#### Prediksi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-QC9pSPHJTg"
      },
      "outputs": [],
      "source": [
        "#hasil sendiri\n",
        "yhat_1 = graf.predict(x)\n",
        "yhat = np.argmax(yhat_1, axis=1)\n",
        "\n",
        "#MLPClassifier\n",
        "yhat_sklearn = sklearn.predict(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Perbandingan confusion matrix dan kinerja dengan sklearn"
      ],
      "metadata": {
        "id": "qcGeGnkTSU0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Pengukuran Kinerja FFNN Hasil Implementasi"
      ],
      "metadata": {
        "id": "IOb0ITXC89iH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fungsi Kinerja Hasil implementasi sendiri\")\n",
        "print(\"Confusion Matrix\")\n",
        "cm =Utils.confusionMatrix(y, yhat)\n",
        "print(cm)\n",
        "print(f\"Accuracy Score: {Utils.accuracy(y, yhat)}\")\n",
        "print(f\"Precision Score: {Utils.precision(y, yhat)}\")\n",
        "print(f\"Recall Score: {Utils.recall(y,yhat)}\")\n",
        "print(f\"F1 Score: {Utils.f1(y, yhat)}\")\n",
        "\n",
        "print()\n",
        "print(\"Fungsi Kinerja Sklearn\")\n",
        "print(\"Confusion Matrix\")\n",
        "print(metrics.confusion_matrix(y,yhat))\n",
        "print(f\"Accuracy Score: {metrics.accuracy_score(y, yhat)}\")\n",
        "print(f\"Precision Score: {metrics.precision_score(y, yhat, average='macro', zero_division=0)}\")\n",
        "print(f\"Recall Score: {metrics.recall_score(y, yhat, average='macro', zero_division=0)}\")\n",
        "print(f\"F1 Score: {metrics.f1_score(y, yhat, average='macro', zero_division=0)}\")"
      ],
      "metadata": {
        "id": "ggRFkJukN3D_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a6efdc0-934f-4188-b6cf-b2919782f805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fungsi Kinerja Hasil implementasi sendiri\n",
            "Confusion Matrix\n",
            "[[50.  0.  0.]\n",
            " [ 0. 49.  1.]\n",
            " [ 0.  0. 50.]]\n",
            "Accuracy Score: 0.9933333333333333\n",
            "Precision Score: 0.9934640522875817\n",
            "Recall Score: 0.9933333333333333\n",
            "F1 Score: 0.9933326665999934\n",
            "\n",
            "Fungsi Kinerja Sklearn\n",
            "Confusion Matrix\n",
            "[[50  0  0]\n",
            " [ 0 49  1]\n",
            " [ 0  0 50]]\n",
            "Accuracy Score: 0.9933333333333333\n",
            "Precision Score: 0.9934640522875817\n",
            "Recall Score: 0.9933333333333333\n",
            "F1 Score: 0.9933326665999934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Pengukuran Kinerja MLPCLassifier Sklearn"
      ],
      "metadata": {
        "id": "faO3erJx9AuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fungsi Kinerja Hasil implementasi sendiri\")\n",
        "print(\"Confusion Matrix\")\n",
        "cm =Utils.confusionMatrix(y, yhat_sklearn)\n",
        "print(cm)\n",
        "print(f\"Accuracy Score: {Utils.accuracy(y, yhat_sklearn)}\")\n",
        "print(f\"Precision Score: {Utils.precision(y, yhat_sklearn)}\")\n",
        "print(f\"Recall Score: {Utils.recall(y,yhat_sklearn)}\")\n",
        "print(f\"F1 Score: {Utils.f1(y, yhat_sklearn)}\")\n",
        "\n",
        "print()\n",
        "print(\"Fungsi Kinerja Sklearn\")\n",
        "print(\"Confusion Matrix\")\n",
        "print(metrics.confusion_matrix(y,yhat_sklearn))\n",
        "print(f\"Accuracy Score: {metrics.accuracy_score(y, yhat_sklearn)}\")\n",
        "print(f\"Precision Score: {metrics.precision_score(y, yhat_sklearn, average='macro', zero_division=0)}\")\n",
        "print(f\"Recall Score: {metrics.recall_score(y, yhat_sklearn, average='macro', zero_division=0)}\")\n",
        "print(f\"F1 Score: {metrics.f1_score(y, yhat_sklearn, average='macro', zero_division=0)}\")"
      ],
      "metadata": {
        "id": "JGS1lZLLg6Z3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e9a1e68-0c23-4531-9f0c-750be173833d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fungsi Kinerja Hasil implementasi sendiri\n",
            "Confusion Matrix\n",
            "[[50.  0.  0.]\n",
            " [ 0. 48.  2.]\n",
            " [ 0.  1. 49.]]\n",
            "Accuracy Score: 0.98\n",
            "Precision Score: 0.980125383486728\n",
            "Recall Score: 0.98\n",
            "F1 Score: 0.97999799979998\n",
            "\n",
            "Fungsi Kinerja Sklearn\n",
            "Confusion Matrix\n",
            "[[50  0  0]\n",
            " [ 0 48  2]\n",
            " [ 0  1 49]]\n",
            "Accuracy Score: 0.98\n",
            "Precision Score: 0.980125383486728\n",
            "Recall Score: 0.98\n",
            "F1 Score: 0.97999799979998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pembelajaran FFNN"
      ],
      "metadata": {
        "id": "jKRsnqSzCiLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Skema Split Train 90%, Test 10%"
      ],
      "metadata": {
        "id": "s5HB23MXCnWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# init & config\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "TRAIN_SIZE = 0.90\n",
        "sklearn_sigmoid = MLPClassifier(hidden_layer_sizes=(3,), activation='logistic', max_iter=10000, batch_size=50, learning_rate='constant', learning_rate_init=1e-2)\n",
        "graf_iris = Graph(len(iris.feature_names), 2, [3, len(iris.target_names)], ['sigmoid', 'softmax'])\n",
        "\n",
        "# split data\n",
        "x_iris_train, x_iris_test, y_iris_train, y_iris_test = train_test_split(x, y, train_size=TRAIN_SIZE)\n",
        "\n",
        "# fit & predict\n",
        "sklearn_fitted = sklearn_sigmoid.fit(x_iris_train, y_iris_train)\n",
        "sklearn_prediction = sklearn_fitted.predict(x_iris_test)\n",
        "\n",
        "graf_iris.train(x_iris_train, y_iris_train.reshape(-1,1), 1e-2, 2e-2,50)\n",
        "graf_prediction_1 = graf.predict(x_iris_test)\n",
        "graf_prediction = np.argmax(graf_prediction_1, axis=1)\n",
        "\n",
        "# kinerja & confusion  matrix\n",
        "yhat = np.argmax(sklearn_prediction)"
      ],
      "metadata": {
        "id": "E5KO-tjVCzSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pengukuran Kinerja FFNN Hasil Implementasi Sendiri"
      ],
      "metadata": {
        "id": "qU4fB7cr9W20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fungsi Kinerja Implementasi Sendiri\")\n",
        "print(\"Confusion Matrix\")\n",
        "print(Utils.confusionMatrix(y_iris_test, graf_prediction))\n",
        "print(f\"Accuracy Score: {Utils.accuracy(y_iris_test, graf_prediction)}\")\n",
        "print(f\"Precision Score: {Utils.precision(y_iris_test, graf_prediction)}\")\n",
        "print(f\"Recall Score: {Utils.recall(y_iris_test, graf_prediction)}\")\n",
        "print(f\"F1 Score: {Utils.f1(y_iris_test, graf_prediction)}\")\n",
        "print()\n",
        "print(\"Fungsi Kinerja Sklearn\")\n",
        "print(\"Confusion Matrix\")\n",
        "print(metrics.confusion_matrix(y_iris_test, graf_prediction))\n",
        "print(f\"Accuracy Score: {metrics.accuracy_score(y_iris_test, graf_prediction)}\")\n",
        "print(f\"Precision Score: {metrics.precision_score(y_iris_test, graf_prediction, average='macro', zero_division=0)}\")\n",
        "print(f\"Recall Score: {metrics.recall_score(y_iris_test, graf_prediction, average='macro', zero_division=0)}\")\n",
        "print(f\"F1 Score: {metrics.f1_score(y_iris_test, graf_prediction, average='macro', zero_division=0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSuXJA7u9VTU",
        "outputId": "eb32e77b-148a-458f-ac69-8d7fd3c4f210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fungsi Kinerja Implementasi Sendiri\n",
            "Confusion Matrix\n",
            "[[5. 0. 0.]\n",
            " [0. 6. 0.]\n",
            " [0. 0. 4.]]\n",
            "Accuracy Score: 1.0\n",
            "Precision Score: 1.0\n",
            "Recall Score: 1.0\n",
            "F1 Score: 1.0\n",
            "\n",
            "Fungsi Kinerja Sklearn\n",
            "Confusion Matrix\n",
            "[[5 0 0]\n",
            " [0 6 0]\n",
            " [0 0 4]]\n",
            "Accuracy Score: 1.0\n",
            "Precision Score: 1.0\n",
            "Recall Score: 1.0\n",
            "F1 Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pengukuran Kinerja FFNN MLPClassifier Sklearn"
      ],
      "metadata": {
        "id": "VGNS5s-h9bP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fungsi Kinerja Implementasi Sendiri\")\n",
        "print(\"Confusion Matrix\")\n",
        "print(Utils.confusionMatrix(y_iris_test, sklearn_prediction))\n",
        "print(f\"Accuracy Score: {Utils.accuracy(y_iris_test, sklearn_prediction)}\")\n",
        "print(f\"Precision Score: {Utils.precision(y_iris_test, sklearn_prediction)}\")\n",
        "print(f\"Recall Score: {Utils.recall(y_iris_test, sklearn_prediction)}\")\n",
        "print(f\"F1 Score: {Utils.f1(y_iris_test, sklearn_prediction)}\")\n",
        "\n",
        "print()\n",
        "print(\"Fungsi Kinerja Sklearn\")\n",
        "print(\"Confusion Matrix\")\n",
        "print(metrics.confusion_matrix(y_iris_test, sklearn_prediction))\n",
        "print(f\"Accuracy Score: {metrics.accuracy_score(y_iris_test, sklearn_prediction)}\")\n",
        "print(f\"Precision Score: {metrics.precision_score(y_iris_test, sklearn_prediction, average='macro', zero_division=0)}\")\n",
        "print(f\"Recall Score: {metrics.recall_score(y_iris_test, sklearn_prediction, average='macro', zero_division=0)}\")\n",
        "print(f\"F1 Score: {metrics.f1_score(y_iris_test, sklearn_prediction, average='macro', zero_division=0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95tbG6TH9lTF",
        "outputId": "c98ad7ae-18e0-4a4a-f3ba-65447c26a80a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fungsi Kinerja Implementasi Sendiri\n",
            "Confusion Matrix\n",
            "[[5. 0. 0.]\n",
            " [0. 5. 1.]\n",
            " [0. 0. 4.]]\n",
            "Accuracy Score: 0.9333333333333333\n",
            "Precision Score: 0.9333333333333332\n",
            "Recall Score: 0.9444444444444445\n",
            "F1 Score: 0.9326599326599326\n",
            "\n",
            "Fungsi Kinerja Sklearn\n",
            "Confusion Matrix\n",
            "[[5 0 0]\n",
            " [0 5 1]\n",
            " [0 0 4]]\n",
            "Accuracy Score: 0.9333333333333333\n",
            "Precision Score: 0.9333333333333332\n",
            "Recall Score: 0.9444444444444445\n",
            "F1 Score: 0.9326599326599326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Skema 10-fold Cross Validation\n"
      ],
      "metadata": {
        "id": "w_LPNf_fCtyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# init & config\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, KFold, StratifiedKFold\n",
        "\n",
        "K_FOLDS = 10\n",
        "kf = StratifiedKFold(n_splits=K_FOLDS)\n",
        "\n",
        "sklearn_sigmoid = MLPClassifier(hidden_layer_sizes=(3,), activation='logistic', max_iter=10000, batch_size=50, learning_rate='constant', learning_rate_init=1e-2)\n",
        "graf_iris = Graph(len(iris.feature_names), 2, [3, len(iris.target_names)], ['sigmoid', 'softmax'])\n",
        "\n",
        "# NOTE: Yang ini versi lebih compact, tapi hasilnya ga bisa dipipeline ke fungsi score yang kita buat\n",
        "# Jadi mungkin yang bakal dipake yang versi manual\n",
        "# scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
        "# scores = cross_validate(sklearn_sigmoid, x, y, scoring=scoring, cv=kf)\n",
        "# print(f'Accuracy: %.3f (%.3f)' % (mean(scores[\"test_accuracy\"]), std(scores[\"test_accuracy\"])))\n",
        "# print(f'Precision: %.3f (%.3f)' % (mean(scores[\"test_precision_macro\"]), std(scores[\"test_precision_macro\"])))\n",
        "# print(f'Recall: %.3f (%.3f)' % (mean(scores[\"test_recall_macro\"]), std(scores[\"test_recall_macro\"])))\n",
        "# print(f'F1: %.3f (%.3f)' % (mean(scores[\"test_f1_macro\"]), std(scores[\"test_f1_macro\"])))\n",
        "\n",
        "# Yang ini versi manual\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "utils_accuracy_scores = []\n",
        "utils_precision_scores = []\n",
        "utils_recall_scores = []\n",
        "utils_f1_scores = []\n",
        "\n",
        "for train_idx, test_idx in kf.split(x, y):\n",
        "  # split data\n",
        "  x_iris_train, x_iris_test, y_iris_train, y_iris_test = x[train_idx], x[test_idx], y[train_idx], y[test_idx]\n",
        "\n",
        "  # fit & predict\n",
        "  sklearn_sigmoid.fit(x_iris_train, y_iris_train)\n",
        "  prediction_values = sklearn_sigmoid.predict(x_iris_test)\n",
        "\n",
        "  graf_iris.train(x_iris_train, y_iris_train.reshape(-1,1), 1e-2, 2e-2,50)\n",
        "  graf_prediction_1 = graf.predict(x_iris_test)\n",
        "  graf_prediction = np.argmax(graf_prediction_1, axis=1)\n",
        "\n",
        "  # Sklearn\n",
        "  accuracy = metrics.accuracy_score(y_iris_test, prediction_values)\n",
        "  precision = metrics.precision_score(y_iris_test, prediction_values, average='macro', zero_division=1)\n",
        "  recall = metrics.recall_score(y_iris_test, prediction_values, average='macro', zero_division=1)\n",
        "  f1 = metrics.f1_score(y_iris_test, prediction_values, average='macro', zero_division=1)\n",
        "\n",
        "  accuracy_scores.append(accuracy)\n",
        "  precision_scores.append(precision)\n",
        "  recall_scores.append(recall)\n",
        "  f1_scores.append(f1)\n",
        "\n",
        "  # Utils\n",
        "  utils_accuracy = Utils.accuracy(y_iris_test, graf_prediction)\n",
        "  utils_precision = Utils.precision(y_iris_test, graf_prediction)\n",
        "  utils_recall = Utils.recall(y_iris_test, graf_prediction)\n",
        "  utils_f1 = Utils.f1(y_iris_test, graf_prediction)\n",
        "\n",
        "  utils_accuracy_scores.append(utils_accuracy)\n",
        "  utils_precision_scores.append(utils_precision)\n",
        "  utils_recall_scores.append(utils_recall)\n",
        "  utils_f1_scores.append(utils_f1)"
      ],
      "metadata": {
        "id": "aqLl_-mtCy6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pengukuran Kinerja FFNN Hasil Implementasi Sendiri"
      ],
      "metadata": {
        "id": "WGDYVqkWAA7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fungsi Kinerja Implementasi Sendiri\")\n",
        "print(f\"(Average) Accuracy Score: {mean(utils_accuracy_scores)}\")\n",
        "print(f\"(Average) Precision Score: {mean(utils_precision_scores)}\")\n",
        "print(f\"(Average) Recall Score: {mean(utils_recall_scores)}\")\n",
        "print(f\"(Average) F1 Score: {mean(utils_f1_scores)}\")\n",
        "\n",
        "print()\n",
        "print(\"Fungsi Kinerja Sklearn\")\n",
        "print(f\"(Average) Accuracy Score: {mean(utils_accuracy_scores)}\")\n",
        "print(f\"(Average) Precision Score: {mean(utils_precision_scores)}\")\n",
        "print(f\"(Average) Recall Score: {mean(utils_recall_scores)}\")\n",
        "print(f\"(Average) F1 Score: {mean(utils_f1_scores)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoycvesCAN2A",
        "outputId": "50deb5d4-79df-4c0e-9f21-8a5e9b45b4f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fungsi Kinerja Implementasi Sendiri\n",
            "(Average) Accuracy Score: 0.9933333333333334\n",
            "(Average) Precision Score: 0.9944444444444445\n",
            "(Average) Recall Score: 0.9933333333333334\n",
            "(Average) F1 Score: 0.9932659932659933\n",
            "\n",
            "Fungsi Kinerja Sklearn\n",
            "(Average) Accuracy Score: 0.9933333333333334\n",
            "(Average) Precision Score: 0.9944444444444445\n",
            "(Average) Recall Score: 0.9933333333333334\n",
            "(Average) F1 Score: 0.9932659932659933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pengukuran Kinerja FFNN MLPClassifier Sklearn"
      ],
      "metadata": {
        "id": "8ChgBYv7AHZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fungsi Kinerja Implementasi Sendiri\")\n",
        "print(f\"(Average) Accuracy Score: {mean(accuracy_scores)}\")\n",
        "print(f\"(Average) Precision Score: {mean(precision_scores)}\")\n",
        "print(f\"(Average) Recall Score: {mean(recall_scores)}\")\n",
        "print(f\"(Average) F1 Score: {mean(f1_scores)}\")\n",
        "\n",
        "print()\n",
        "print(\"Fungsi Kinerja Sklearn\")\n",
        "print(f\"(Average) Accuracy Score: {mean(accuracy_scores)}\")\n",
        "print(f\"(Average) Precision Score: {mean(precision_scores)}\")\n",
        "print(f\"(Average) Recall Score: {mean(recall_scores)}\")\n",
        "print(f\"(Average) F1 Score: {mean(f1_scores)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJj7CS9jAOvx",
        "outputId": "b053db7b-272b-4c06-d1ca-726f56b7e842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fungsi Kinerja Implementasi Sendiri\n",
            "(Average) Accuracy Score: 0.9800000000000001\n",
            "(Average) Precision Score: 0.9811111111111112\n",
            "(Average) Recall Score: 0.9800000000000001\n",
            "(Average) F1 Score: 0.97993265993266\n",
            "\n",
            "Fungsi Kinerja Sklearn\n",
            "(Average) Accuracy Score: 0.9800000000000001\n",
            "(Average) Precision Score: 0.9811111111111112\n",
            "(Average) Recall Score: 0.9800000000000001\n",
            "(Average) F1 Score: 0.97993265993266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Instance* Baru"
      ],
      "metadata": {
        "id": "QkGze8yvsGqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_graf = Graph(file_name=\"model.json\")"
      ],
      "metadata": {
        "id": "Q53G7mjMBPY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_values = new_graf.predict(np.array([[6.6, 3.1, 5.7, 2.3],[4.4, 2.1, 1.5, 0.3],[5.6, 2.9, 4.3, 1.5],[5.3, 3.9, 1.3, 0.5]]))\n",
        "yhat_2 = np.argmax(pred_values, axis=1)\n",
        "\n",
        "correct_answers = [2,0,1,0]\n",
        "print(\"Confusion Matrix\")\n",
        "print(Utils.confusionMatrix(correct_answers, yhat_2))\n",
        "print(f\"Accuracy Score: {Utils.accuracy(correct_answers, yhat_2)}\")\n",
        "print(f\"Precision Score: {Utils.precision(correct_answers, yhat_2)}\")\n",
        "print(f\"Recall Score: {Utils.recall(correct_answers, yhat_2)}\")\n",
        "print(f\"F1 Score: {Utils.f1(correct_answers, yhat_2)}\")"
      ],
      "metadata": {
        "id": "KF3jBvP5MEOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abbbc4f8-9ff5-473b-de84-429d0f2df6b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Accuracy Score: 1.0\n",
            "Precision Score: 1.0\n",
            "Recall Score: 1.0\n",
            "F1 Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analisis Perbandingan *Confusion Matrix* dan Perhitungan Kinerja"
      ],
      "metadata": {
        "id": "eq7S_KEjC0XV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Skema *Batch***\n",
        "- | Confusion Matrix dan Kinerja Hasil Implementasi | Confusion Matrix dan Kinerja Sklearn\n",
        "--|--|--|\n",
        "FFNN Hasil Implementasi | <table><tr><td>*Confusion Matrix*</td><td>$$\\begin{bmatrix}50. & 0. & 0.\\\\0. & 49. & 1.\\\\0. & 0. & 50.\\end{bmatrix}$$</td></tr><tr><td>*Accuracy Score*</td><td>0.9933333333333333</td></tr><tr><td>*Precision Score*</td><td>0.9934640522875817</td></tr><tr><td>*Recall Score*</td><td>0.9933333333333333</td></tr><tr><td>*F1 Score*</td><td>0.9933326665999934</td></tr></table> | <table><tr><td>*Confusion Matrix*</td><td>$$\\begin{bmatrix}50 & 0 & 0\\\\0 & 49 & 1\\\\0 & 0 & 50\\end{bmatrix}$$</td></tr><tr><td>*Accuracy Score*</td><td>0.9933333333333333</td></tr><tr><td>*Precision Score*</td><td>0.9934640522875817</td></tr><tr><td>*Recall Score*</td><td>0.9933333333333333</td></tr><tr><td>*F1 Score*</td><td>0.9933326665999934</td></tr></table>\n",
        "MLPCLassifier Sklearn | <table><tr><td>*Confusion Matrix*</td><td>$$\\begin{bmatrix}50. & 0. & 0.\\\\0. & 48. & 2.\\\\0. & 1. & 49.\\end{bmatrix}$$</td></tr><tr><td>*Accuracy Score*</td><td>0.98</td></tr><tr><td>*Precision Score*</td><td>0.980125383486728</td></tr><tr><td>*Recall Score*</td><td>0.98</td></tr><tr><td>*F1 Score*</td><td>0.97999799979998</td></tr></table> | <table><tr><td>*Confusion Matrix*</td><td>$$\\begin{bmatrix}50 & 0 & 0\\\\0 & 48 & 2\\\\0 & 1 & 49\\end{bmatrix}$$</td></tr><tr><td>*Accuracy Score*</td><td>0.98</td></tr><tr><td>*Precision Score*</td><td>0.980125383486728</td></tr><tr><td>*Recall Score*</td><td>0.98</td></tr><tr><td>*F1 Score*</td><td>0.97999799979998</td></tr></table>\n",
        "\n",
        "\n",
        "### **Skema *Split***\n",
        "- | Confusion Matrix dan Kinerja Hasil Implementasi | Confusion Matrix dan Kinerja Sklearn\n",
        "--|--|--|\n",
        "FFNN Hasil Implementasi | <table><tr><td>*Confusion Matrix*</td><td>$$\\begin{bmatrix}5. & 0. & 0.\\\\0. & 6. & 0.\\\\0. & 0. & 4.\\end{bmatrix}$$</td></tr><tr><td>*Accuracy Score*</td><td>1.0</td></tr><tr><td>*Precision Score*</td><td>1.0</td></tr><tr><td>*Recall Score*</td><td>1.0</td></tr><tr><td>*F1 Score*</td><td>1.0</td></tr></table> | <table><tr><td>*Confusion Matrix*</td><td>$$\\begin{bmatrix}5 & 0 & 0\\\\0 & 6 & 0\\\\0 & 0 & 4\\end{bmatrix}$$</td></tr><tr><td>*Accuracy Score*</td><td>1.0</td></tr><tr><td>*Precision Score*</td><td>1.0</td></tr><tr><td>*Recall Score*</td><td>1.0</td></tr><tr><td>*F1 Score*</td><td>1.0</td></tr></table>\n",
        "MLPCLassifier Sklearn | <table><tr><td>*Confusion Matrix*</td><td>$$\\begin{bmatrix}5. & 0. & 0.\\\\0. & 5. & 1.\\\\0. & 0. & 4.\\end{bmatrix}$$</td></tr><tr><td>*Accuracy Score*</td><td>0.9333333333333333</td></tr><tr><td>*Precision Score*</td><td>0.9333333333333332</td></tr><tr><td>*Recall Score*</td><td>0.9444444444444445</td></tr><tr><td>*F1 Score*</td><td>0.9326599326599326</td></tr></table> | <table><tr><td>*Confusion Matrix*</td><td>$$\\begin{bmatrix}5 & 0 & 0\\\\0 & 5 & 1\\\\0 & 0 & 4\\end{bmatrix}$$</td></tr><tr><td>*Accuracy Score*</td><td>0.9333333333333333</td></tr><tr><td>*Precision Score*</td><td>0.9333333333333332</td></tr><tr><td>*Recall Score*</td><td>0.9444444444444445</td></tr><tr><td>*F1 Score*</td><td>0.9326599326599326</td></tr></table>\n",
        "\n",
        "Berdasarkan hasil _confusion matrix_ dan kinerja FFNN dan MLPClassifier Sklearn pada skema batch dan skema split, FFNN hasil implementasi kami menghasilkan prediksi yang lebih baik karena memiliki _confusion matrix_ yang lebih bagus dan kinerja yang lebih tinggi. Dapat dilihat juga bahwa hasil implementasi fungsi kinerja kami menghasilkan nilai yang sesuai dengan fungsi kinerja Sklearn."
      ],
      "metadata": {
        "id": "nPcIXamCC7oK"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TubesC_13519096",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}